{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5410d-f4b5-4f90-81c7-3be170af5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from PY_tweet.lists_file import dumpJoblib, loadJoblib\n",
    "\n",
    "data = loadJoblib('../DATA_all_texts/only_4labels_textdata.joblib')\n",
    "label = loadJoblib('../DATA_all_texts/only_4labels_label.joblib')\n",
    "\n",
    "from PY_preprocessing import remove\n",
    "\n",
    "rm = remove.Remove()\n",
    "data = rm.covid19(data)\n",
    "\n",
    "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.7\n",
    "\n",
    "import random \n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from PY_classification.multi_classification import BertForSequenceClassificationMultiLabel\n",
    "\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_scml = BertForSequenceClassificationMultiLabel(\n",
    "    MODEL_NAME, num_labels=4\n",
    ") \n",
    "bert_scml = bert_scml.to(device=device)\n",
    "\n",
    "\n",
    "labels = []\n",
    "for emotion in label:\n",
    "    if emotion == 63:\n",
    "        labels.append([1, 0, 0, 0])\n",
    "    elif emotion == 64:\n",
    "        labels.append([0, 1, 0, 0])\n",
    "    elif emotion == 65:\n",
    "        labels.append([0, 0, 1, 0])\n",
    "    else:\n",
    "        labels.append([0, 0, 0, 1])\n",
    "\n",
    "max_length = 152\n",
    "dataset_for_loader = []\n",
    "\n",
    "for text, label in zip(data, labels):\n",
    "    encoding = tokenizer(\n",
    "      text, \n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "    )\n",
    "    encoding['labels'] = label\n",
    "    encoding = {k: torch.tensor(v).to(device=device) for k, v in encoding.items() }\n",
    "    dataset_for_loader.append(encoding)\n",
    "    \n",
    "\n",
    "random.shuffle(dataset_for_loader)\n",
    "n = len(dataset_for_loader)\n",
    "n_train = int(0.6*n)\n",
    "n_val = int(0.2*n)\n",
    "dataset_train = dataset_for_loader[:n_train]\n",
    "dataset_val = dataset_for_loader[n_train:n_train+n_val]\n",
    "dataset_test = dataset_for_loader[n_train+n_val:]\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=16, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val, batch_size=16\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test, batch_size=16\n",
    ")\n",
    "\n",
    "dataloader_val\n",
    "\n",
    "from PY_classification.pytorch_lightning_multi import BertForSequenceClassificationMultiLabel_pl\n",
    "\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath='part/model/'\n",
    ")\n",
    "\n",
    "#学習方法指定\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassificationMultiLabel_pl(\n",
    "    MODEL_NAME, num_labels=4, lr=1e-5\n",
    ")\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "\n",
    "best_model_path = checkpoint.best_model_path\n",
    "print(f'validation data loss:{checkpoint.best_model_score}')\n",
    "print(f'The best path is {best_model_path}')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./\n",
    "\n",
    "test = trainer.test(test_dataloaders=dataloader_test, ckpt_path=best_model_path)\n",
    "print(f'Accuracy: {test[0][\"accuracy\"]:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
